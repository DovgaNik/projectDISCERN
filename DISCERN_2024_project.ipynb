{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PMh_yax3zXm"
   },
   "source": [
    "Project for DISCERN 2024\n",
    "===\n",
    "\n",
    "This project is supposed to use [gpt2 model from huggingface](https://huggingface.co/openai-community/gpt2) and then use train data from [kaggle](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets) to detect fake and true information in news and articles. The articles used for checking collected by our team [are here](https://unirau-my.sharepoint.com/:x:/g/personal/dovhan_o_nikita22_stud_rau_ro/EVZaoVJ1OIFFmkT7ognXzbcBiR8JDDXK-ID0DWAdiFnMvg?e=DTESAz).\n",
    "\n",
    "Main inspiration taken from the [folder of this programme](https://unirau-my.sharepoint.com/personal/andrei_luchici_rau_ro/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fandrei%5Fluchici%5Frau%5Fro%2FDocuments%2F24%2D02%2D05%20%2D%20DISCERN%20%2D%20Ed%201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NBTOh1nu0MS-",
    "ExecuteTime": {
     "end_time": "2024-02-09T07:58:02.112275800Z",
     "start_time": "2024-02-09T07:57:36.691238800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model, TFGPT2ForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T07:58:02.135601400Z",
     "start_time": "2024-02-09T07:58:02.116986500Z"
    }
   },
   "outputs": [],
   "source": [
    "true_file = \"data/True.csv\"\n",
    "fake_file = \"data/Fake.csv\"\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model_dir = \"results/3.model\"\n",
    "\n",
    "amount_of_entries = 5000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T07:58:04.508878400Z",
     "start_time": "2024-02-09T07:58:02.132302700Z"
    }
   },
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(true_file)\n",
    "fake_df = pd.read_csv(fake_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T07:58:04.541539800Z",
     "start_time": "2024-02-09T07:58:04.515006500Z"
    }
   },
   "outputs": [],
   "source": [
    "true_df[\"label\"] = 1\n",
    "fake_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T07:58:04.591254700Z",
     "start_time": "2024-02-09T07:58:04.531940200Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "combined_df = combined_df.head(amount_of_entries)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# in the true dataset all the articles are supplied with the name of the city and the news agancy so in the early models it has learnt that true news differe from fake ones by the availability of CITY (NEWS AGENCY) - in the beginning of the article\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: re.sub(r'^[A-Z\\s]+\\([A-Za-z\\s]+\\)\\s*-\\s*', '', x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T07:58:04.665510600Z",
     "start_time": "2024-02-09T07:58:04.575109Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T07:58:04.673819500Z",
     "start_time": "2024-02-09T07:58:04.617311300Z"
    }
   },
   "outputs": [],
   "source": [
    "# splittin data into train and test one\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    combined_df[\"text\"].values,\n",
    "    combined_df[\"label\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T20:50:59.763298100Z",
     "start_time": "2024-02-08T20:50:57.635438900Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='tf')\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='tf')\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Classifier(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GPT2Classifier, self).__init__()\n",
    "        self.gpt2 = TFGPT2Model.from_pretrained(model_name)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.6)\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.gpt2(inputs)[0]\n",
    "        pooled_output = tf.reduce_mean(outputs, axis=1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "model = GPT2Classifier(num_classes=2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset.shuffle(5000).batch(batch_size), epochs=3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset.batch(batch_size))\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ],
   "metadata": {},
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the model\n",
    "==="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict_news_class(probabilities, threshold=0.5):\n",
    "    fake_probability, true_probability = probabilities[0]\n",
    "    if fake_probability > threshold:\n",
    "        return \"fake\"\n",
    "    else:\n",
    "        return \"true\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T21:12:07.473872Z",
     "start_time": "2024-02-08T21:12:07.464190700Z"
    }
   },
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:1113: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_dir)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T20:50:30.485362200Z",
     "start_time": "2024-02-08T20:50:18.745208700Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'true'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(input(), return_tensors='tf', max_length=512, truncation=True, padding='max_length')\n",
    "output = model(inputs)\n",
    "predict_news_class(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T21:13:07.932530200Z",
     "start_time": "2024-02-08T21:13:05.707653900Z"
    }
   },
   "execution_count": 60
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
