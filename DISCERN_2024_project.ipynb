{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PMh_yax3zXm"
   },
   "source": [
    "Project for DISCERN 2024\n",
    "===\n",
    "\n",
    "This project is supposed to use [gpt2 model from huggingface](https://huggingface.co/openai-community/gpt2) and then use train data from [kaggle](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets) to detect fake and true information in news and articles. The articles used for checking collected by our team [are here](https://unirau-my.sharepoint.com/:x:/g/personal/dovhan_o_nikita22_stud_rau_ro/EVZaoVJ1OIFFmkT7ognXzbcBiR8JDDXK-ID0DWAdiFnMvg?e=DTESAz).\n",
    "\n",
    "Main inspiration taken from the [folder of this programme](https://unirau-my.sharepoint.com/personal/andrei_luchici_rau_ro/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fandrei%5Fluchici%5Frau%5Fro%2FDocuments%2F24%2D02%2D05%20%2D%20DISCERN%20%2D%20Ed%201)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2fLMyCix58S",
    "outputId": "e0ad5e6b-0099-42a1-96dd-9e21723e0bcc"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NBTOh1nu0MS-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4eed4dd2-1563-4e40-c107-7068f1b41d5d",
    "ExecuteTime": {
     "end_time": "2024-02-08T23:53:09.330879500Z",
     "start_time": "2024-02-08T23:52:44.530916600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nikit\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciuFNAXGuEWD"
   },
   "source": [
    "Parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "K8YFlbaXuEWE",
    "ExecuteTime": {
     "end_time": "2024-02-08T23:53:53.084773600Z",
     "start_time": "2024-02-08T23:53:53.058112Z"
    }
   },
   "outputs": [],
   "source": [
    "#true_file = \"/content/drive/MyDrive/mount/True.csv\"\n",
    "#fake_file = \"/content/drive/MyDrive/mount/Fake.csv\"\n",
    "\n",
    "true_file = \"data/True.csv\"\n",
    "fake_file = \"data/Fake.csv\"\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model_dir = \"results/modelcollab5k\"\n",
    "\n",
    "amount_of_entries = 3000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def augment_text(text):\n",
    "    words = text.split()\n",
    "    augmented_text = []\n",
    "    for word in words:\n",
    "        augmented_text.append(word)\n",
    "        if random.random() < 0.6:  # 20% chance for augmentation\n",
    "            synonym = find_synonym(word)\n",
    "            if synonym:\n",
    "                augmented_text[-1] = synonym\n",
    "        if random.random() < 0.3:  # 10% chance for augmentation\n",
    "            random_word = random.choice(words)\n",
    "            augmented_text.append(random_word)\n",
    "    return ' '.join(augmented_text)"
   ],
   "metadata": {
    "id": "lTfauDxT7xtm"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def find_synonym(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    if len(synonyms) > 1:\n",
    "        return random.choice(list(synonyms - {word}))\n",
    "    else:\n",
    "        return None\n"
   ],
   "metadata": {
    "id": "XWw3uvHZ71WP"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:52:52.537552600Z",
     "start_time": "2024-02-08T21:52:51.492323200Z"
    },
    "id": "VSji7860uEWF"
   },
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(true_file)\n",
    "fake_df = pd.read_csv(fake_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:52:52.606098400Z",
     "start_time": "2024-02-08T21:52:52.594668100Z"
    },
    "id": "JDREI4m6uEWH"
   },
   "outputs": [],
   "source": [
    "true_df[\"label\"] = 1\n",
    "fake_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:52:52.606098400Z",
     "start_time": "2024-02-08T21:52:52.597829200Z"
    },
    "id": "HjdRTVAIuEWH"
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "combined_df = combined_df.head(amount_of_entries)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "combined_df['text'] = combined_df['text'].apply(lambda x: re.sub(r'^[A-Z\\s]+\\([A-Za-z\\s]+\\)\\s*-\\s*', '', x))\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x.lower()))  # Remove punctuation and lowercase\n",
    "combined_df['text'] = combined_df['text'].apply(augment_text)  # Data augmentation"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:52:52.606098400Z",
     "start_time": "2024-02-08T21:52:52.597829200Z"
    },
    "id": "x1spRlpCuEWI"
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:52:52.611145800Z",
     "start_time": "2024-02-08T21:52:52.606098400Z"
    },
    "id": "tjJB55PtuEWJ"
   },
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    combined_df[\"text\"].values,\n",
    "    combined_df[\"label\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXd67hpWuEWK",
    "outputId": "4a547acd-0884-469a-c75c-df54cb50b659",
    "ExecuteTime": {
     "end_time": "2024-02-08T23:54:36.333288400Z",
     "start_time": "2024-02-08T23:54:34.217920800Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:52:58.875887200Z",
     "start_time": "2024-02-08T21:52:53.696874100Z"
    },
    "id": "t_LnwMxnuEWK"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='tf')\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='tf')\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:53:01.546208Z",
     "start_time": "2024-02-08T21:52:58.875887200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVRTWOJtuEWL",
    "outputId": "a1e27e77-2ddd-4729-ea76-3b1473ca835b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2Model.\n",
      "\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class GPT2Classifier(tf.keras.Model):\n",
    "    def __init__(self, num_classes, l2_lambda=0.1):\n",
    "        super(GPT2Classifier, self).__init__()\n",
    "        self.gpt2 = TFGPT2Model.from_pretrained(model_name)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.6)\n",
    "        self.dense = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                           kernel_regularizer=tf.keras.regularizers.L2(l2_lambda))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.gpt2(inputs)[0]\n",
    "        pooled_output = tf.reduce_mean(outputs, axis=1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.dense(pooled_output)\n",
    "        return logits\n",
    "\n",
    "model = GPT2Classifier(num_classes=2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-08T21:53:01.546208Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePrMeO96uEWM",
    "outputId": "5813ec2f-c7d1-4fde-cfc8-e7eae1ada257"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "300/300 [==============================] - 341s 1s/step - loss: 1.6383 - accuracy: 0.7600\n",
      "Epoch 2/3\n",
      "300/300 [==============================] - 317s 1s/step - loss: 0.5635 - accuracy: 0.9379\n",
      "Epoch 3/3\n",
      "300/300 [==============================] - 318s 1s/step - loss: 0.4275 - accuracy: 0.9654\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7e0dc472f700>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.fit(train_dataset.shuffle(1000).batch(batch_size), epochs=3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1MEcqA25uEWN"
   },
   "outputs": [],
   "source": [
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyjUsuinuEWM",
    "outputId": "52a4689f-f1f9-4512-9dd8-395d1933c522"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10/19 [==============>...............] - ETA: 12s - loss: 0.4859 - accuracy: 0.9500"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset.batch(32))\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBGFNKlduEWN"
   },
   "source": [
    "Testing\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:1113: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n"
     ]
    }
   ],
   "source": [
    "def predict_news_class(probabilities, threshold=0.5):\n",
    "    fake_probability, true_probability = probabilities[0]\n",
    "    if fake_probability > threshold:\n",
    "        return \"fake\"\n",
    "    else:\n",
    "        return \"true\"\n",
    "\n",
    "model = tf.keras.models.load_model(model_dir)"
   ],
   "metadata": {
    "id": "4rYZu--zuEWN",
    "ExecuteTime": {
     "end_time": "2024-02-08T23:54:19.950866100Z",
     "start_time": "2024-02-08T23:54:04.371674300Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'fake'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(input(), return_tensors='tf', max_length=512, truncation=True, padding='max_length')\n",
    "output = model(inputs)\n",
    "predict_news_class(output)"
   ],
   "metadata": {
    "id": "ZMwfeTwruEWO",
    "ExecuteTime": {
     "end_time": "2024-02-08T23:56:08.722680200Z",
     "start_time": "2024-02-08T23:56:06.949586Z"
    }
   },
   "execution_count": 12
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
