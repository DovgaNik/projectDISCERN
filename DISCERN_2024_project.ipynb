{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PMh_yax3zXm"
   },
   "source": [
    "Project for DISCERN 2024\n",
    "===\n",
    "\n",
    "This project is supposed to use [gpt2 model from huggingface](https://huggingface.co/openai-community/gpt2) and then use train data from [kaggle](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets) to detect fake and true information in news and articles. The articles used for checking collected by our team [are here](https://unirau-my.sharepoint.com/:x:/g/personal/dovhan_o_nikita22_stud_rau_ro/EVZaoVJ1OIFFmkT7ognXzbcBiR8JDDXK-ID0DWAdiFnMvg?e=DTESAz).\n",
    "\n",
    "Main inspiration taken from the [folder of this programme](https://unirau-my.sharepoint.com/personal/andrei_luchici_rau_ro/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fandrei%5Fluchici%5Frau%5Fro%2FDocuments%2F24%2D02%2D05%20%2D%20DISCERN%20%2D%20Ed%201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NBTOh1nu0MS-",
    "ExecuteTime": {
     "end_time": "2024-02-08T20:49:30.124376200Z",
     "start_time": "2024-02-08T20:49:30.114708900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model, TFGPT2ForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T20:49:31.633639300Z",
     "start_time": "2024-02-08T20:49:31.619367800Z"
    }
   },
   "outputs": [],
   "source": [
    "true_file = \"data/True.csv\"\n",
    "fake_file = \"data/Fake.csv\"\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model_dir = \"results/2.model\"\n",
    "\n",
    "amount_of_entries = 1500\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(true_file)\n",
    "fake_df = pd.read_csv(fake_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df[\"label\"] = 1\n",
    "fake_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "combined_df = combined_df.head(amount_of_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    combined_df[\"text\"].values,\n",
    "    combined_df[\"label\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T20:50:59.763298100Z",
     "start_time": "2024-02-08T20:50:57.635438900Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='tf')\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='tf')\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Classifier(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GPT2Classifier, self).__init__()\n",
    "        self.gpt2 = TFGPT2Model.from_pretrained(model_name)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.6)\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.gpt2(inputs)[0]\n",
    "        pooled_output = tf.reduce_mean(outputs, axis=1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "model = GPT2Classifier(num_classes=2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset.shuffle(1000).batch(batch_size), epochs=2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset.batch(32))\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict_news_class(probabilities, threshold=0.5):\n",
    "    fake_probability, true_probability = probabilities[0]\n",
    "    if fake_probability > threshold:\n",
    "        return \"fake\"\n",
    "    else:\n",
    "        return \"true\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T21:12:07.473872Z",
     "start_time": "2024-02-08T21:12:07.464190700Z"
    }
   },
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "WARNING:tensorflow:From D:\\winterSchoolRAUFebruary\\project\\env\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:1113: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_dir)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T20:50:30.485362200Z",
     "start_time": "2024-02-08T20:50:18.745208700Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'true'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(input(), return_tensors='tf', max_length=512, truncation=True, padding='max_length')\n",
    "output = model(inputs)\n",
    "predict_news_class(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T21:13:07.932530200Z",
     "start_time": "2024-02-08T21:13:05.707653900Z"
    }
   },
   "execution_count": 60
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
